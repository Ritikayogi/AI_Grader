ğŸ¤– AI Auto-Grader
ğŸ¯ Project Overview

The AI Auto-Grader is an intelligent system that automatically evaluates and grades studentsâ€™ answers by comparing them with ideal solutions.
It uses Groqâ€™s Llama-3.1 large language model to assess the correctness, completeness, and reasoning quality of a studentâ€™s response â€” and assigns marks accordingly.

This project was developed as a demonstration of how Generative AI can automate academic grading efficiently and consistently.

âš™ï¸ Tech Stack
Component	Technology Used
AI Model	Groq Llama-3.1 (via Groq API)
Programming Language	Python 3.13
Frontend Interface	Streamlit
Text Extraction	Tesseract OCR, pdfplumber
Data Handling	Pandas, OpenPyXL
File Format	XLSX (Excel Dataset)
ğŸ§  How It Works

Extracts questions, ideal answers, and student answers from PDFs or Excel sheets.

Sends each questionâ€“answer pair to Groqâ€™s Llama-3.1 model.

The model evaluates the response for:

Concept understanding

Accuracy and completeness

Depth of reasoning

Returns:

âœ… Marks obtained

ğŸ’¬ Reason for grading

Stores all results into a structured Excel file: graded_output_groq.xlsx.

ğŸ“‚ Folder Structure
AI_Grader/
â”œâ”€â”€ app.py                     # Streamlit web interface
â”œâ”€â”€ grading_model_groq.py      # Core AI grading logic using Groq
â”œâ”€â”€ extract_dataset_ocr.py     # Extracts text from PDFs (QP, MS, CP)
â”œâ”€â”€ training_data_all.xlsx     # Dataset: Questions + Answers
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # Documentation file (this one)
â”œâ”€â”€ Maanya_*.pdf               # Sample Question/Mark Scheme/Checked Papers
â””â”€â”€ graded_output_groq.xlsx    # AI-generated results

ğŸš€ Run Locally
1ï¸âƒ£ Clone or Extract the Project

If using GitHub:

git clone https://github.com/Ritikayogi/AI_Grader.git
cd AI_Grader


If using ZIP:

Unzip AI_Grader.zip

Open the folder in terminal or VS Code

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

3ï¸âƒ£ Add Your Groq API Key

Create a file named .env in the same directory and add:

GROQ_API_KEY = "your_groq_api_key_here"

4ï¸âƒ£ Run the AI Grader
python grading_model_groq.py --input "training_data_all.xlsx" --output "graded_output.xlsx"


After execution, the system will generate a new file:

graded_output.xlsx


containing marks and reasoning for each answer.

ğŸ–¥ï¸ (Optional) Run the Streamlit Web App

You can also use the project with a clean web UI.

streamlit run app.py


Then open the link shown in your terminal (usually http://localhost:8501
).
Upload your Excel dataset â†’ click Grade Answers â†’ view results interactively.

ğŸ§ª Example Output
Question	Ideal_Answer	Student_Answer	Marks	Reasoning
Q1	Explain Binomial Theorem.	A binomial expansion shows combinations...	3/4	Answer mostly correct, missed one detail.
Q2	Define Normal Distribution.	It shows a bell-shaped curve.	1/2	Too short, lacks proper reasoning.
ğŸ’¡ Key Features

âœ… Works for any subject (Math, Science, etc.)
âœ… Reads answers from PDFs or Excel files
âœ… Uses Groq Llama-3.1 for high-speed evaluation
âœ… Generates detailed reasoning with marks
âœ… Easy to extend for future fine-tuning

ğŸ§‘â€ğŸ’» Author

Ritika Yogi
ğŸ“§ yogiritika02@gmail.com

ğŸ’¼ GitHub: Ritikayogi

ğŸ Future Improvements

Add automatic question type detection (MCQ / Subjective / Numerical)

Improve scoring logic for long answers

Add analytics dashboard (accuracy, average score trends)

Support batch grading across multiple subjects

ğŸ§© Sample Run Commands

For quick testing:

# Extract data from PDFs (if needed)
python extract_dataset_ocr.py

# Run the AI grading model
python grading_model_groq.py --input "training_data_all.xlsx" --output "graded_output_groq.xlsx"

ğŸ§­ Project Workflow Diagram
PDF / Excel
     â”‚
     â–¼
 Extract Text (OCR / pdfplumber)
     â”‚
     â–¼
 Compare â†’ Groq Llama-3.1 Model
     â”‚
     â–¼
 Generate Marks + Reasoning
     â”‚
     â–¼
 Save as graded_output.xlsx

ğŸ† Result

A fully functional AI-powered automated grading system
that can check descriptive answers, give scores, and explain its reasoning â€”
reducing manual checking time by over 80% âš¡
